{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COS 429 Final Project\n",
    "## VGG Face\n",
    "\n",
    "Initial setup:\n",
    "- Create instance (p2.xlarge)\n",
    "- `scp` the .caffemodel and .prototxt files over\n",
    "- Create ssl cert and password for Jupyter notebook\n",
    "\n",
    "To get this up and running on AWS (after initial setup):\n",
    "- `sudo ssh -i thesis.pem -L 443:127.0.0.1:8888 ubuntu@...`\n",
    "- `127.0.0.1`\n",
    "- Password: cos429_russakovsky\n",
    "- `source activate theano_p36`\n",
    "- `conda install -c anaconda pillow`\n",
    "- `conda install h5py`\n",
    "- `conda install scikit-learn`\n",
    "- `conda install -c pchrapka matlab_kernel`\n",
    "- `jupyter notebook`\n",
    "- `scp -i cos429.pem *.py ubuntu@...:~/cos429/`\n",
    "\n",
    "This uses the Keras weights (hard to get caffemodel and t7 files working for caffe2/pytorch) for VGG_FACE, which was converted from vgg-face matconvnet model using as shown here: https://gist.github.com/EncodeTS/6bbe8cb8bebad7a672f0d872561782d9.\n",
    "\n",
    "Before stopping the instance, remember to download the latest .ipynb file for the GitHub. Terminate the instance to delete all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys  \n",
    "# os.environ['THEANO_FLAGS'] = \"device=gpu1\"    \n",
    "# import theano\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'vgg-face-keras.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This network architecture is derived from Table 3 of the CNN described in Parkhi et al. \n",
    "# and based on Keras code provided in https://gist.github.com/EncodeTS/6bbe8cb8bebad7a672f0d872561782d9\n",
    "\n",
    "def vgg_face(weights_path=None):\n",
    "    img = Input(shape=(3, 224, 224))\n",
    "\n",
    "    pad1_1 = ZeroPadding2D(padding=(1, 1))(img)\n",
    "    conv1_1 = Convolution2D(64, (3, 3), activation='relu', name='conv1_1')(pad1_1)\n",
    "    pad1_2 = ZeroPadding2D(padding=(1, 1))(conv1_1)\n",
    "    conv1_2 = Convolution2D(64, (3, 3), activation='relu', name='conv1_2')(pad1_2)\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2, 2))(conv1_2)\n",
    "\n",
    "    pad2_1 = ZeroPadding2D((1, 1))(pool1)\n",
    "    conv2_1 = Convolution2D(128, (3, 3), activation='relu', name='conv2_1')(pad2_1)\n",
    "    pad2_2 = ZeroPadding2D((1, 1))(conv2_1)\n",
    "    conv2_2 = Convolution2D(128, (3, 3), activation='relu', name='conv2_2')(pad2_2)\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2))(conv2_2)\n",
    "\n",
    "    pad3_1 = ZeroPadding2D((1, 1))(pool2)\n",
    "    conv3_1 = Convolution2D(256, (3, 3), activation='relu', name='conv3_1')(pad3_1)\n",
    "    pad3_2 = ZeroPadding2D((1, 1))(conv3_1)\n",
    "    conv3_2 = Convolution2D(256, (3, 3), activation='relu', name='conv3_2')(pad3_2)\n",
    "    pad3_3 = ZeroPadding2D((1, 1))(conv3_2)\n",
    "    conv3_3 = Convolution2D(256, (3, 3), activation='relu', name='conv3_3')(pad3_3)\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2))(conv3_3)\n",
    "\n",
    "    pad4_1 = ZeroPadding2D((1, 1))(pool3)\n",
    "    conv4_1 = Convolution2D(512, (3, 3), activation='relu', name='conv4_1')(pad4_1)\n",
    "    pad4_2 = ZeroPadding2D((1, 1))(conv4_1)\n",
    "    conv4_2 = Convolution2D(512, (3, 3), activation='relu', name='conv4_2')(pad4_2)\n",
    "    pad4_3 = ZeroPadding2D((1, 1))(conv4_2)\n",
    "    conv4_3 = Convolution2D(512, (3, 3), activation='relu', name='conv4_3')(pad4_3)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4_3)\n",
    "\n",
    "    pad5_1 = ZeroPadding2D((1, 1))(pool4)\n",
    "    conv5_1 = Convolution2D(512, (3, 3), activation='relu', name='conv5_1')(pad5_1)\n",
    "    pad5_2 = ZeroPadding2D((1, 1))(conv5_1)\n",
    "    conv5_2 = Convolution2D(512, (3, 3), activation='relu', name='conv5_2')(pad5_2)\n",
    "    pad5_3 = ZeroPadding2D((1, 1))(conv5_2)\n",
    "    conv5_3 = Convolution2D(512, (3, 3), activation='relu', name='conv5_3')(pad5_3)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2))(conv5_3)\n",
    "\n",
    "    # These layers are used in the original VGG Face paper for their dataset of 2,622 individuals\n",
    "    # The output of the previous layer is the 4096-dimensional face descriptor\n",
    "    fc6 = Convolution2D(4096, (7, 7), activation='relu', name='fc6')(pool5)\n",
    "    fc6_drop = Dropout(0.5)(fc6)\n",
    "    fc7 = Convolution2D(4096, (1, 1), activation='relu', name='fc7')(fc6_drop)\n",
    "    fc7_drop = Dropout(0.5)(fc7)\n",
    "    fc8 = Convolution2D(2622, (1, 1), name='fc8')(fc7_drop)\n",
    "    flat = Flatten()(fc8)\n",
    "    out = Activation('softmax')(flat)\n",
    "\n",
    "    model = Model(inputs=img, outputs=out)\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Returns model that for the 4096-dimensional face descriptor \n",
    "def partial_vgg_face():\n",
    "    model = vgg_face(weights_path)\n",
    "    layer_name = 'fc7'\n",
    "    partial_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "    return partial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model by passing an image through it\n",
    "im = Image.open('A.J._Buckley.jpg')\n",
    "im = im.resize((224,224))\n",
    "im = np.array(im).astype(np.float32)\n",
    "# im[:,:,0] -= 129.1863\n",
    "# im[:,:,1] -= 104.7624\n",
    "# im[:,:,2] -= 93.5940\n",
    "im = im.transpose((2,0,1))\n",
    "im = np.expand_dims(im, axis=0)\n",
    "print('Shape:', im.shape)\n",
    "\n",
    "model = vgg_face(weights_path)\n",
    "out = model.predict(im)\n",
    "print(out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the partial model by passing an image through it\n",
    "model = partial_vgg_face()\n",
    "im = Image.open('A.J._Buckley.jpg')\n",
    "im = im.resize((224,224))\n",
    "im = np.array(im).astype(np.float32)\n",
    "im = im.transpose((2,0,1))\n",
    "im = np.expand_dims(im, axis=0)\n",
    "\n",
    "descriptor = model.predict(im)\n",
    "print(descriptor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 3, 226, 226)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 64, 226, 226)      0         \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 64, 114, 114)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 256, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "fc6 (Conv2D)                 (None, 4096, 1, 1)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "fc7 (Conv2D)                 (None, 4096, 1, 1)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "fc8 (Conv2D)                 (None, 2622, 1, 1)        10742334  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2622)              0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = vgg_face(weights_path)\n",
    "print(model.summary())\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "% load_ext autoreload\n",
    "% aimport experiment\n",
    "% aimport manipulations\n",
    "% autoreload 1\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy import ndimage\n",
    "from scipy.stats import mode\n",
    "\n",
    "import manipulations\n",
    "import experiment\n",
    "from manipulations import ManipulationInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulations\n",
    "# Based on Cathy's manipulations.py\n",
    "\n",
    "def perform_manipulation(data, manipulation_info: ManipulationInfo):\n",
    "    manipulation_type = manipulation_info.type\n",
    "    manipulation_parameters = manipulation_info.parameters\n",
    "    if manipulation_type == \"none\":\n",
    "        return data\n",
    "    elif manipulation_type == \"occlude_lfw\":\n",
    "        occlusion_size = manipulation_parameters[\"occlusion_size\"]\n",
    "        return occlude_lfw_dataset(data, occlusion_size)\n",
    "    elif manipulation_type == \"radial_distortion\":\n",
    "        k = manipulation_parameters[\"k\"]\n",
    "        return radially_distort_lfw_dataset(data, k)\n",
    "    elif manipulation_type == \"blur\":\n",
    "        blurwindow_size = manipulation_parameters[\"blurwindow_size\"]\n",
    "        return blur_lfw_dataset(data, blurwindow_size)\n",
    "    else:\n",
    "        raise Exception(\"UNKNOWN MANIPULATION.\")\n",
    "        \n",
    "def occlude_lfw_dataset(data, occlusion_size):\n",
    "    num_images = data.shape[0]\n",
    "    dataset_images = [add_occlusion(data[i], occlusion_size) for i in range(num_images)]\n",
    "    return np.asarray(dataset_images)\n",
    "\n",
    "def add_occlusion(input_image, occlusion_size):\n",
    "    \"\"\"Randomly selects an occlusion_size-by-occlusion_size square in the image\n",
    "    and sets the pixels to random values between 0 and 256. Same value for all 3 channels.\"\"\"\n",
    "    max_value = 256\n",
    "    max_i, max_j, ch = input_image.shape\n",
    "    input_image = np.copy(input_image)\n",
    "    start_i = np.random.randint(0, max_i-occlusion_size)\n",
    "    start_j = np.random.randint(0, max_j-occlusion_size)\n",
    "    occlusion_square = np.random.rand(occlusion_size, occlusion_size)*max_value\n",
    "    input_image[start_i:start_i+occlusion_size,start_j:start_j+occlusion_size,0]=occlusion_square\n",
    "    input_image[start_i:start_i+occlusion_size,start_j:start_j+occlusion_size,1]=occlusion_square\n",
    "    input_image[start_i:start_i+occlusion_size,start_j:start_j+occlusion_size,2]=occlusion_square\n",
    "    return input_image\n",
    "\n",
    "def radially_distort_lfw_dataset(data, k):\n",
    "    lfw_imageshape = (224, 224)\n",
    "    distortion_array_i, distortion_array_j = create_radial_distortion_array(k, lfw_imageshape)\n",
    "    num_images = data.shape[0]\n",
    "    dataset_images = [radial_distortion(data[i], distortion_array_i, distortion_array_j) for i in range(num_images)]\n",
    "    return np.asarray(dataset_images)\n",
    "\n",
    "def radial_distortion(input_image, distortion_array_i, distortion_array_j):\n",
    "    distorted_image = np.empty(input_image.shape)\n",
    "    for i in range(distorted_image.shape[0]):\n",
    "        for j in range(distorted_image.shape[1]):\n",
    "            input_i = distortion_array_i[i, j]\n",
    "            input_j = distortion_array_j[i, j]\n",
    "            distorted_image[i,j,0] = input_image[input_i, input_j,0]\n",
    "            distorted_image[i,j,1] = input_image[input_i, input_j,1]\n",
    "            distorted_image[i,j,2] = input_image[input_i, input_j,2]\n",
    "    return distorted_image\n",
    "\n",
    "def create_radial_distortion_array(k, input_image_shape):\n",
    "    # http://sprg.massey.ac.nz/pdfs/2003_IVCNZ_408.pdf\n",
    "    # x_d = x_u / (1+kr_d^2)\n",
    "    # Negative k for pincushion, positive k for barrel.\n",
    "    i_max, j_max = input_image_shape\n",
    "    i0 = int(i_max / 2)\n",
    "    j0 = int(j_max / 2)\n",
    "    distortion_array_i = np.zeros(input_image_shape, dtype='int')\n",
    "    distortion_array_j = np.zeros(input_image_shape, dtype='int')\n",
    "    for i in range(i_max):\n",
    "        for j in range(j_max):\n",
    "            i_bar = i - i0\n",
    "            j_bar = j - j0\n",
    "            r_squared = (i_bar * i_bar) + (j_bar * j_bar)\n",
    "            i_input = i / (1+k*r_squared)\n",
    "            j_input = j / (1+k*r_squared)\n",
    "            if i_input < i_max and j_input < j_max and i_input >= 0 and j_input >= 0:\n",
    "                distortion_array_i[i, j] = i_input\n",
    "                distortion_array_j[i, j] = j_input\n",
    "    return distortion_array_i, distortion_array_j\n",
    "\n",
    "def blur_lfw_dataset(data, blurwindow_size):\n",
    "    num_images = data.shape[0]\n",
    "    dataset_images = [blur(data[i], blurwindow_size) for i in range(num_images)]\n",
    "    return np.asarray(dataset_images)\n",
    "\n",
    "def blur(input_image, blurwindow_size):\n",
    "    blurred_image = np.empty(input_image.shape)\n",
    "    blurred_image[:,:,0] = ndimage.percentile_filter(input_image[:,:,0], -50, blurwindow_size)\n",
    "    blurred_image[:,:,1] = ndimage.percentile_filter(input_image[:,:,1], -50, blurwindow_size)\n",
    "    blurred_image[:,:,2] = ndimage.percentile_filter(input_image[:,:,2], -50, blurwindow_size)\n",
    "    return blurred_image\n",
    "\n",
    "def blur_slow(input_image, blurwindow_size):\n",
    "    blurred_image = np.empty(input_image.shape)\n",
    "    blurwindow_halflength = blurwindow_size / 2\n",
    "    image_imax, image_jmax = input_image.shape\n",
    "    for i in range(image_imax):\n",
    "        for j in range(image_jmax):\n",
    "            blurwindow_imin = int(max(0, i-blurwindow_halflength))\n",
    "            blurwindow_jmin = int(max(0, j-blurwindow_halflength))\n",
    "            blurwindow_imax = int(min(image_imax, i+blurwindow_halflength))\n",
    "            blurwindow_jmax = int(min(image_jmax, j+blurwindow_halflength))\n",
    "            blurred_image[i,j,0] = np.mean(input_image[blurwindow_imin:blurwindow_imax,blurwindow_jmin:blurwindow_jmax,0])\n",
    "            blurred_image[i,j,1] = np.mean(input_image[blurwindow_imin:blurwindow_imax,blurwindow_jmin:blurwindow_jmax,1])\n",
    "            blurred_image[i,j,2] = np.mean(input_image[blurwindow_imin:blurwindow_imax,blurwindow_jmin:blurwindow_jmax,2])\n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test manipulations\n",
    "\n",
    "im = Image.open('A.J._Buckley.jpg')\n",
    "im = im.resize((224,224))\n",
    "im = np.array(im).astype(np.float32)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "\n",
    "#         ManipulationInfo(\"none\", {}),\n",
    "#         ManipulationInfo(\"occlude_lfw\", {\"occlusion_size\": 20}),\n",
    "#         ManipulationInfo(\"occlude_lfw\", {\"occlusion_size\": 10}),\n",
    "#         ManipulationInfo(\"occlude_lfw\", {\"occlusion_size\": 30}),\n",
    "#         ManipulationInfo(\"occlude_lfw\", {\"occlusion_size\": 40}),\n",
    "#         ManipulationInfo(\"radial_distortion\", {\"k\": 0.00015}),\n",
    "#         ManipulationInfo(\"radial_distortion\", {\"k\": -0.00015}),\n",
    "#         ManipulationInfo(\"radial_distortion\", {\"k\": 0.0003}),\n",
    "#         ManipulationInfo(\"radial_distortion\", {\"k\": -0.0003}),\n",
    "#         ManipulationInfo(\"radial_distortion\", {\"k\": 0.0005}),\n",
    "#         ManipulationInfo(\"radial_distortion\", {\"k\": -0.0005}),\n",
    "#         ManipulationInfo(\"blur\", {\"blurwindow_size\": 5}),\n",
    "#         ManipulationInfo(\"blur\", {\"blurwindow_size\": 10})\n",
    "\n",
    "imM = perform_manipulation(im, ManipulationInfo(\"radial_distortion\", {\"k\": 0.00003}))\n",
    "plt.imshow(imM[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LFW dataset\n",
    "\n",
    "def get_lfw_dataset(min_faces_per_person, manipulation_info: ManipulationInfo):\n",
    "    dataset = fetch_lfw_people(\n",
    "        min_faces_per_person=min_faces_per_person, \n",
    "        color=True, \n",
    "        slice_=(slice(0, 250, None), slice(0, 250, None)), \n",
    "        resize=0.896)\n",
    "    data = dataset.images\n",
    "    # data = manipulations.perform_manipulation(data, manipulation_info)\n",
    "    # mean_face = np.mean(data, axis=0)\n",
    "    # data = data - mean_face\n",
    "\n",
    "    train_indices, test_indices = experiment.split_traintest(dataset.target)\n",
    "    train_data = data[train_indices,:]\n",
    "    train_targets = dataset.target[train_indices]\n",
    "    test_data = perform_manipulation(data[test_indices,:], manipulation_info)\n",
    "    test_targets = dataset.target[test_indices]\n",
    "\n",
    "    # test_data = normalize(test_data, axis=1)\n",
    "    # train_data = normalize(train_data, axis=1)\n",
    "    # train_data, test_data, train_targets, test_targets = train_test_split(data, dataset.target)\n",
    "    \n",
    "    mean_face = [129.1863, 104.7624, 93.5940] # BGR\n",
    "    \n",
    "    train_data = train_data.transpose((0,3,1,2))\n",
    "    train_data[:,0,:,:] = train_data[:,0,:,:] - mean_face[0]\n",
    "    train_data[:,1,:,:] = train_data[:,1,:,:] - mean_face[1]\n",
    "    train_data[:,2,:,:] = train_data[:,2,:,:] - mean_face[2]\n",
    "#     train_data = train_data[:,::-1,:,:] # Flip to RGB? \n",
    "# Confusing because it seems like fetch_lfw_people() does some things to the original image \n",
    "# (coloring is off and the pixels are 0-255, not 0-1 as stated in documentation/their code)\n",
    "    \n",
    "    test_data = test_data.transpose((0,3,1,2))\n",
    "    test_data[:,0,:,:] = test_data[:,0,:,:] - mean_face[0]\n",
    "    test_data[:,1,:,:] = test_data[:,1,:,:] - mean_face[1]\n",
    "    test_data[:,2,:,:] = test_data[:,2,:,:] - mean_face[2]\n",
    "#     test_data = train_data[:,::-1,:,:] # Flip to RGB?\n",
    "    \n",
    "    return train_data, train_targets, test_data, test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptors(model, data):    \n",
    "    descriptors = model.predict(data, verbose=1)\n",
    "    return np.squeeze(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with nearest-k neighbors and cosine similarity\n",
    "def predict(train_descriptors, test_descriptors, k, num_examples_per_face, threshold=None):\n",
    "    predictions = []\n",
    "   \n",
    "    for d in test_descriptors:\n",
    "        # Use cosine similarity\n",
    "        distances = [cosine(train_descriptors[i], d) for i in range(len(train_descriptors))]\n",
    "        \n",
    "        # The closest k vote instead of average\n",
    "        closest_k = np.asarray(distances).argsort()[:k] // num_examples_per_face\n",
    "        predictions.append(mode(closest_k).mode)\n",
    "    return np.asarray(predictions).flatten()\n",
    "\n",
    "# Alternative prediction method with average and L2 Euclidean distance\n",
    "def predict_with_mean(train_descriptors, test_descriptors, num_examples_per_face, threshold=None):\n",
    "    predictions = []\n",
    "    mean_train_descriptors = np.mean(np.reshape(train_descriptors, (-1, num_examples_per_face, 4096)), axis=1)\n",
    "   \n",
    "    for d in test_descriptors:\n",
    "        distances = [np.linalg.norm(mean_train_descriptors[i] - d) for i in range(len(mean_train_descriptors))]\n",
    "        predictions.append(np.argmin(distances))\n",
    "    return np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(manipulation_info: ManipulationInfo):\n",
    "    print('Loading model')\n",
    "    model = partial_vgg_face()\n",
    "    \n",
    "    print('Loading dataset')\n",
    "    min_faces_per_person = 20\n",
    "    train_data, train_targets, test_data, test_targets = get_lfw_dataset(\n",
    "        min_faces_per_person, manipulation_info=manipulation_info)\n",
    "    \n",
    "    # Train\n",
    "    print('Training')\n",
    "    time1 = time.clock()\n",
    "    num_faces = len(np.unique(train_targets))\n",
    "    num_examples_per_face = int(len(train_targets) / num_faces)\n",
    "    train_descriptors = get_descriptors(model, train_data)\n",
    "    test_descriptors = get_descriptors(model, test_data)\n",
    "    time2 = time.clock()\n",
    "    train_time = time2 - time1\n",
    "    \n",
    "    # Test\n",
    "    print('Testing')\n",
    "    time1 = time.clock()\n",
    "    train_predictions_1 = predict(train_descriptors, train_descriptors, 1, num_examples_per_face)\n",
    "    train_predictions_3 = predict(train_descriptors, train_descriptors, 3, num_examples_per_face)\n",
    "    train_predictions_5 = predict(train_descriptors, train_descriptors, 5, num_examples_per_face)\n",
    "    train_predictions_7 = predict(train_descriptors, train_descriptors, 7, num_examples_per_face)\n",
    "    # train_accuracy = experiment.compute_accuracy(train_predictions, test_targets)\n",
    "    train_accuracy_1 = experiment.compute_accuracy(train_predictions_1, train_targets)\n",
    "    train_accuracy_3 = experiment.compute_accuracy(train_predictions_3, train_targets)\n",
    "    train_accuracy_5 = experiment.compute_accuracy(train_predictions_5, train_targets)\n",
    "    train_accuracy_7 = experiment.compute_accuracy(train_predictions_7, train_targets)\n",
    "    \n",
    "    # Predict test_descriptors\n",
    "    test_predictions_1 = predict(train_descriptors, test_descriptors, 1, num_examples_per_face)\n",
    "    test_predictions_3 = predict(train_descriptors, test_descriptors, 3, num_examples_per_face)\n",
    "    test_predictions_5 = predict(train_descriptors, test_descriptors, 5, num_examples_per_face)\n",
    "    test_predictions_7 = predict(train_descriptors, test_descriptors, 7, num_examples_per_face)\n",
    "    # test_accuracy = experiment.compute_accuracy(test_predictions, test_targets)\n",
    "    test_accuracy_1 = experiment.compute_accuracy(test_predictions_1, test_targets)\n",
    "    test_accuracy_3 = experiment.compute_accuracy(test_predictions_3, test_targets)\n",
    "    test_accuracy_5 = experiment.compute_accuracy(test_predictions_5, test_targets)\n",
    "    test_accuracy_7 = experiment.compute_accuracy(test_predictions_7, test_targets)\n",
    "    time2 = time.clock()\n",
    "    test_time = time2 - time1\n",
    "    \n",
    "    train_accuracy = { \"k=1\": train_accuracy_1, \n",
    "                      \"k=3\": train_accuracy_3, \n",
    "                      \"k=5\": train_accuracy_5, \n",
    "                      \"k=7\": train_accuracy_7 }\n",
    "    \n",
    "    test_accuracy = { \"k=1\": test_accuracy_1, \n",
    "                      \"k=3\": test_accuracy_3, \n",
    "                      \"k=5\": test_accuracy_5, \n",
    "                      \"k=7\": test_accuracy_7 }\n",
    "    \n",
    "    # Print results.\n",
    "    num_faces = len(np.unique(train_targets))\n",
    "    model_name = 'VGG_FACE'\n",
    "    print(\"Manipulation info: %s\" % str(manipulation_info))\n",
    "    print(\"Recognition Algorithm: %s\" % model_name)\n",
    "    print(\"Number of distinct faces: %d\" % num_faces)\n",
    "    print(\"Chance rate: %f\" % (1 / num_faces))\n",
    "    print(\"Train accuracy: %s\" % train_accuracy)\n",
    "    print(\"Test accuracy: %s\" % test_accuracy)\n",
    "    print(\"Training Time: %s sec\" % train_time)\n",
    "    print(\"Testing Time: %s sec\" % test_time)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"Manipulation Type\": manipulation_info.type,\n",
    "        \"Manipulation Parameters\": manipulation_info.parameters,\n",
    "        \"Recognition Algorithm\": model_name,\n",
    "        \"Min Faces Per Person\": min_faces_per_person,\n",
    "        \"Number of Distinct Faces\": num_faces,\n",
    "        \"Chance Rate\": (1 / num_faces),\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy,\n",
    "        \"Training Time\": train_time,\n",
    "        \"Testing Time\": test_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 82s 439ms/step\n",
      "2837/2837 [==============================] - 1244s 439ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='none', parameters={})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.8808600634473035, 'k=3': 0.83785689108212902, 'k=5': 0.83080719069439546, 'k=7': 0.79978850898836795}\n",
      "Training Time: 2606.5933480000003 sec\n",
      "Testing Time: 151.603744 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'none', 'Manipulation Parameters': {}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.8808600634473035, 'k=3': 0.83785689108212902, 'k=5': 0.83080719069439546, 'k=7': 0.79978850898836795}, 'Training Time': 2606.5933480000003, 'Testing Time': 151.603744}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 81s 437ms/step\n",
      "2837/2837 [==============================] - 1242s 438ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='occlude_lfw', parameters={'occlusion_size': 82})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.50546351780049348, 'k=3': 0.50863588297497353, 'k=5': 0.51039830807190689, 'k=7': 0.49841381741275997}\n",
      "Training Time: 2601.8876450000007 sec\n",
      "Testing Time: 152.4791810000006 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'occlude_lfw', 'Manipulation Parameters': {'occlusion_size': 82}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.50546351780049348, 'k=3': 0.50863588297497353, 'k=5': 0.51039830807190689, 'k=7': 0.49841381741275997}, 'Training Time': 2601.8876450000007, 'Testing Time': 152.4791810000006}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 82s 439ms/step\n",
      "2837/2837 [==============================] - 1243s 438ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='occlude_lfw', parameters={'occlusion_size': 41})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.81424039478322174, 'k=3': 0.788861473387381, 'k=5': 0.79062389848431447, 'k=7': 0.75995770179767363}\n",
      "Training Time: 2603.7390259999993 sec\n",
      "Testing Time: 152.2700909999985 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'occlude_lfw', 'Manipulation Parameters': {'occlusion_size': 41}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.81424039478322174, 'k=3': 0.788861473387381, 'k=5': 0.79062389848431447, 'k=7': 0.75995770179767363}, 'Training Time': 2603.7390259999993, 'Testing Time': 152.2700909999985}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 82s 439ms/step\n",
      "2837/2837 [==============================] - 1243s 438ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='occlude_lfw', parameters={'occlusion_size': 124})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.048995417694747974, 'k=3': 0.057455058160028195, 'k=5': 0.074726824109975332, 'k=7': 0.087768769827282336}\n",
      "Training Time: 2604.8532459999988 sec\n",
      "Testing Time: 150.4129350000003 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'occlude_lfw', 'Manipulation Parameters': {'occlusion_size': 124}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.048995417694747974, 'k=3': 0.057455058160028195, 'k=5': 0.074726824109975332, 'k=7': 0.087768769827282336}, 'Training Time': 2604.8532459999988, 'Testing Time': 150.4129350000003}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 82s 440ms/step\n",
      "2837/2837 [==============================] - 1244s 438ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='occlude_lfw', parameters={'occlusion_size': 165})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.018329221008107157, 'k=3': 0.013394430736693691, 'k=5': 0.023616496298907295, 'k=7': 0.030313711667254141}\n",
      "Training Time: 2605.79752 sec\n",
      "Testing Time: 148.3748749999977 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'occlude_lfw', 'Manipulation Parameters': {'occlusion_size': 165}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.018329221008107157, 'k=3': 0.013394430736693691, 'k=5': 0.023616496298907295, 'k=7': 0.030313711667254141}, 'Training Time': 2605.79752, 'Testing Time': 148.3748749999977}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 82s 440ms/step\n",
      "2837/2837 [==============================] - 1249s 440ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='radial_distortion', parameters={'k': 8e-06})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.88579485371871691, 'k=3': 0.85195629185759603, 'k=5': 0.84208671131476909, 'k=7': 0.8198801550934085}\n",
      "Training Time: 2613.6003740000015 sec\n",
      "Testing Time: 150.44535099999848 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'radial_distortion', 'Manipulation Parameters': {'k': 8e-06}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.88579485371871691, 'k=3': 0.85195629185759603, 'k=5': 0.84208671131476909, 'k=7': 0.8198801550934085}, 'Training Time': 2613.6003740000015, 'Testing Time': 150.44535099999848}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 79s 424ms/step\n",
      "2837/2837 [==============================] - 1202s 424ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='radial_distortion', parameters={'k': -8e-06})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.8523087768769827, 'k=3': 0.81071554458935491, 'k=5': 0.788861473387381, 'k=7': 0.76136764187522032}\n",
      "Training Time: 2524.611495000001 sec\n",
      "Testing Time: 151.04932499999995 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'radial_distortion', 'Manipulation Parameters': {'k': -8e-06}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.8523087768769827, 'k=3': 0.81071554458935491, 'k=5': 0.788861473387381, 'k=7': 0.76136764187522032}, 'Training Time': 2524.611495000001, 'Testing Time': 151.04932499999995}\n",
      "\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 80s 428ms/step\n",
      "2837/2837 [==============================] - 1224s 432ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='radial_distortion', parameters={'k': 1.6e-05})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.84913641170250265, 'k=3': 0.81952767007402183, 'k=5': 0.82798731053930208, 'k=7': 0.81247796968628838}\n",
      "Training Time: 2564.8442450000002 sec\n",
      "Testing Time: 151.21806800000195 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'radial_distortion', 'Manipulation Parameters': {'k': 1.6e-05}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.84913641170250265, 'k=3': 0.81952767007402183, 'k=5': 0.82798731053930208, 'k=7': 0.81247796968628838}, 'Training Time': 2564.8442450000002, 'Testing Time': 151.21806800000195}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 82s 439ms/step\n",
      "2837/2837 [==============================] - 1243s 438ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='radial_distortion', parameters={'k': -1.6e-05})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.80789566443426153, 'k=3': 0.74832569615791333, 'k=5': 0.74515333098343317, 'k=7': 0.71060979908353894}\n",
      "Training Time: 2603.1384839999955 sec\n",
      "Testing Time: 153.34491599999456 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'radial_distortion', 'Manipulation Parameters': {'k': -1.6e-05}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.80789566443426153, 'k=3': 0.74832569615791333, 'k=5': 0.74515333098343317, 'k=7': 0.71060979908353894}, 'Training Time': 2603.1384839999955, 'Testing Time': 153.34491599999456}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 79s 426ms/step\n",
      "2837/2837 [==============================] - 1212s 427ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='radial_distortion', parameters={'k': 3e-05})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.71483961931617901, 'k=3': 0.71801198449065917, 'k=5': 0.73140641522735284, 'k=7': 0.72541416989777929}\n",
      "Training Time: 2543.1018010000043 sec\n",
      "Testing Time: 151.77147200000036 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'radial_distortion', 'Manipulation Parameters': {'k': 3e-05}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.71483961931617901, 'k=3': 0.71801198449065917, 'k=5': 0.73140641522735284, 'k=7': 0.72541416989777929}, 'Training Time': 2543.1018010000043, 'Testing Time': 151.77147200000036}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 81s 437ms/step\n",
      "2837/2837 [==============================] - 1240s 437ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='radial_distortion', parameters={'k': -3e-05})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.65244977088473743, 'k=3': 0.6140289037715897, 'k=5': 0.60592174832569612, 'k=7': 0.57701797673598876}\n",
      "Training Time: 2596.5479300000006 sec\n",
      "Testing Time: 151.69865999999456 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'radial_distortion', 'Manipulation Parameters': {'k': -3e-05}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.65244977088473743, 'k=3': 0.6140289037715897, 'k=5': 0.60592174832569612, 'k=7': 0.57701797673598876}, 'Training Time': 2596.5479300000006, 'Testing Time': 151.69865999999456}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 80s 427ms/step\n",
      "2837/2837 [==============================] - 1211s 427ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='blur', parameters={'blurwindow_size': 5})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.84384913641170245, 'k=3': 0.80613323933732817, 'k=5': 0.79555868875572788, 'k=7': 0.77194219245682061}\n",
      "Training Time: 2540.785076 sec\n",
      "Testing Time: 152.7480460000006 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'blur', 'Manipulation Parameters': {'blurwindow_size': 5}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.84384913641170245, 'k=3': 0.80613323933732817, 'k=5': 0.79555868875572788, 'k=7': 0.77194219245682061}, 'Training Time': 2540.785076, 'Testing Time': 152.7480460000006}\n",
      "\n",
      "Loading model\n",
      "Loading dataset\n",
      "Training\n",
      "186/186 [==============================] - 81s 433ms/step\n",
      "2837/2837 [==============================] - 1228s 433ms/step\n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='blur', parameters={'blurwindow_size': 10})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}\n",
      "Test accuracy: {'k=1': 0.6140289037715897, 'k=3': 0.57067324638702854, 'k=5': 0.57701797673598876, 'k=7': 0.56926330630948185}\n",
      "Training Time: 2574.4263499999943 sec\n",
      "Testing Time: 153.9114580000023 sec\n",
      "\n",
      "\n",
      "{'Manipulation Type': 'blur', 'Manipulation Parameters': {'blurwindow_size': 10}, 'Recognition Algorithm': 'VGG_FACE', 'Min Faces Per Person': 20, 'Number of Distinct Faces': 62, 'Chance Rate': 0.016129032258064516, 'Train Accuracy': {'k=1': 1.0, 'k=3': 0.89784946236559138, 'k=5': 0.86021505376344087, 'k=7': 0.83333333333333337}, 'Test Accuracy': {'k=1': 0.6140289037715897, 'k=3': 0.57067324638702854, 'k=5': 0.57701797673598876, 'k=7': 0.56926330630948185}, 'Training Time': 2574.4263499999943, 'Testing Time': 153.9114580000023}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "manipulation_infos = [\n",
    "        ManipulationInfo(\"none\", {}),\n",
    "        ManipulationInfo(\"occlude_lfw\", {\"occlusion_size\": 82}), # Adjusted for new image size\n",
    "        ManipulationInfo(\"occlude_lfw\", {\"occlusion_size\": 41}),\n",
    "        ManipulationInfo(\"occlude_lfw\", {\"occlusion_size\": 124}),\n",
    "        ManipulationInfo(\"occlude_lfw\", {\"occlusion_size\": 165}),\n",
    "        ManipulationInfo(\"radial_distortion\", {\"k\": 0.000008}), # Adjusted for new image size\n",
    "        ManipulationInfo(\"radial_distortion\", {\"k\": -0.000008}),\n",
    "        ManipulationInfo(\"radial_distortion\", {\"k\": 0.000016}),\n",
    "        ManipulationInfo(\"radial_distortion\", {\"k\": -0.000016}),\n",
    "        ManipulationInfo(\"radial_distortion\", {\"k\": 0.00003}),\n",
    "        ManipulationInfo(\"radial_distortion\", {\"k\": -0.00003}),\n",
    "        ManipulationInfo(\"blur\", {\"blurwindow_size\": 5}),\n",
    "        ManipulationInfo(\"blur\", {\"blurwindow_size\": 10})\n",
    "    ]\n",
    "\n",
    "for manipulation in manipulation_infos:\n",
    "    stats = run_experiment(manipulation)\n",
    "    print(stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff99ca5d8d0>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9953a2c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphs\n",
    "\n",
    "# Accuracy as a function of k\n",
    "\n",
    "k = np.array([1, 3, 5, 7])\n",
    "accuracy = np.array([1.0, 0.89784946236559138, 0.86021505376344087, 0.83333333333333337])\n",
    "\n",
    "plt.plot(k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:theano_p36]",
   "language": "python",
   "name": "conda-env-theano_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
