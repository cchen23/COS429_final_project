{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COS 429 Final Project\n",
    "## VGG Face - DFI Manipulations\n",
    "\n",
    "AWS setup:\n",
    "- `source activate theano_p36`\n",
    "- `conda install -c anaconda pillow`\n",
    "- `conda install h5py`\n",
    "- `conda install scikit-learn`\n",
    "- `jupyter notebook`\n",
    "- `scp -i cos429.pem *.py ubuntu@...:~/cos429/`\n",
    "\n",
    "Download the VGG-FACE pre-trained weights for Keras here: https://drive.google.com/file/d/0B4ChsjFJvew3NkF0dTc1OGxsOFU/view.\n",
    "\n",
    "Before stopping the instance, remember to download the latest .ipynb file for the GitHub. Terminate the instance to delete all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once at start of program\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys  \n",
    "# os.environ['THEANO_FLAGS'] = \"device=gpu1\"    \n",
    "# import theano\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'vgg/vgg-face-keras.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This network architecture is derived from Table 3 of the CNN described in Parkhi et al. \n",
    "# and based on Keras code provided in https://gist.github.com/EncodeTS/6bbe8cb8bebad7a672f0d872561782d9\n",
    "\n",
    "def vgg_face(weights_path=None):\n",
    "    img = Input(shape=(3, 224, 224))\n",
    "\n",
    "    pad1_1 = ZeroPadding2D(padding=(1, 1))(img)\n",
    "    conv1_1 = Convolution2D(64, (3, 3), activation='relu', name='conv1_1')(pad1_1)\n",
    "    pad1_2 = ZeroPadding2D(padding=(1, 1))(conv1_1)\n",
    "    conv1_2 = Convolution2D(64, (3, 3), activation='relu', name='conv1_2')(pad1_2)\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2, 2))(conv1_2)\n",
    "\n",
    "    pad2_1 = ZeroPadding2D((1, 1))(pool1)\n",
    "    conv2_1 = Convolution2D(128, (3, 3), activation='relu', name='conv2_1')(pad2_1)\n",
    "    pad2_2 = ZeroPadding2D((1, 1))(conv2_1)\n",
    "    conv2_2 = Convolution2D(128, (3, 3), activation='relu', name='conv2_2')(pad2_2)\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2))(conv2_2)\n",
    "\n",
    "    pad3_1 = ZeroPadding2D((1, 1))(pool2)\n",
    "    conv3_1 = Convolution2D(256, (3, 3), activation='relu', name='conv3_1')(pad3_1)\n",
    "    pad3_2 = ZeroPadding2D((1, 1))(conv3_1)\n",
    "    conv3_2 = Convolution2D(256, (3, 3), activation='relu', name='conv3_2')(pad3_2)\n",
    "    pad3_3 = ZeroPadding2D((1, 1))(conv3_2)\n",
    "    conv3_3 = Convolution2D(256, (3, 3), activation='relu', name='conv3_3')(pad3_3)\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2))(conv3_3)\n",
    "\n",
    "    pad4_1 = ZeroPadding2D((1, 1))(pool3)\n",
    "    conv4_1 = Convolution2D(512, (3, 3), activation='relu', name='conv4_1')(pad4_1)\n",
    "    pad4_2 = ZeroPadding2D((1, 1))(conv4_1)\n",
    "    conv4_2 = Convolution2D(512, (3, 3), activation='relu', name='conv4_2')(pad4_2)\n",
    "    pad4_3 = ZeroPadding2D((1, 1))(conv4_2)\n",
    "    conv4_3 = Convolution2D(512, (3, 3), activation='relu', name='conv4_3')(pad4_3)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4_3)\n",
    "\n",
    "    pad5_1 = ZeroPadding2D((1, 1))(pool4)\n",
    "    conv5_1 = Convolution2D(512, (3, 3), activation='relu', name='conv5_1')(pad5_1)\n",
    "    pad5_2 = ZeroPadding2D((1, 1))(conv5_1)\n",
    "    conv5_2 = Convolution2D(512, (3, 3), activation='relu', name='conv5_2')(pad5_2)\n",
    "    pad5_3 = ZeroPadding2D((1, 1))(conv5_2)\n",
    "    conv5_3 = Convolution2D(512, (3, 3), activation='relu', name='conv5_3')(pad5_3)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2))(conv5_3)\n",
    "\n",
    "    # These layers are used in the original VGG Face paper for their dataset of 2,622 individuals\n",
    "    # The output of the previous layer is the 4096-dimensional face descriptor\n",
    "    fc6 = Convolution2D(4096, (7, 7), activation='relu', name='fc6')(pool5)\n",
    "    fc6_drop = Dropout(0.5)(fc6)\n",
    "    fc7 = Convolution2D(4096, (1, 1), activation='relu', name='fc7')(fc6_drop)\n",
    "    fc7_drop = Dropout(0.5)(fc7)\n",
    "    fc8 = Convolution2D(2622, (1, 1), name='fc8')(fc7_drop)\n",
    "    flat = Flatten()(fc8)\n",
    "    out = Activation('softmax')(flat)\n",
    "\n",
    "    model = Model(inputs=img, outputs=out)\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Returns model that for the 4096-dimensional face descriptor \n",
    "def partial_vgg_face():\n",
    "    model = vgg_face(weights_path)\n",
    "    layer_name = 'fc7'\n",
    "    partial_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "    return partial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% aimport experiment\n",
    "% aimport manipulations\n",
    "% autoreload 1\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy import ndimage\n",
    "from scipy.stats import mode\n",
    "import h5py\n",
    "\n",
    "import manipulations\n",
    "import experiment\n",
    "from manipulations import ManipulationInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainedModel:\n",
    "    def __init__(self, num_train):\n",
    "        self.num_train = num_train\n",
    "        \n",
    "        print('Loading model')\n",
    "        self.model = partial_vgg_face()\n",
    "        \n",
    "        print('Loading training dataset')\n",
    "        self.min_faces_per_person = 20\n",
    "        self.train_data, self.train_targets, _, _ = experiment.get_lfw_dataset(self.min_faces_per_person, num_train, color=True, size=224)\n",
    "        \n",
    "        # Train\n",
    "        print('Training')\n",
    "        time1 = time.clock()\n",
    "        self.num_faces = len(np.unique(self.train_targets))\n",
    "        self.num_examples_per_face = int(len(self.train_targets) / self.num_faces)\n",
    "        self.train_descriptors = self.get_descriptors(self.train_data)\n",
    "        time2 = time.clock()\n",
    "        self.train_time = time2 - time1\n",
    "        print('Training time: %f' % self.train_time)\n",
    "\n",
    "    # Prediction with nearest-k neighbors and cosine similarity\n",
    "    def predict(self, test_descriptors, k):\n",
    "        predictions = []\n",
    "\n",
    "        for d in test_descriptors:\n",
    "            # Use cosine similarity\n",
    "            distances = [cosine(self.train_descriptors[i], d) for i in range(len(self.train_descriptors))]\n",
    "\n",
    "            # The closest k vote instead of average\n",
    "            closest_k = np.asarray(distances).argsort()[:k] // self.num_examples_per_face\n",
    "            predictions.append(mode(closest_k).mode)\n",
    "        return np.asarray(predictions).flatten()\n",
    "\n",
    "    def predict_train(self, k):\n",
    "        return self.predict(self.train_descriptors, k)\n",
    "\n",
    "    def get_descriptors(self, data):\n",
    "        data = data.transpose((0, 3, 1, 2))\n",
    "        descriptors = self.model.predict(data, verbose=1)\n",
    "        return np.squeeze(descriptors)\n",
    "\n",
    "    # Alternative prediction method with average and L2 Euclidean distance\n",
    "    # def predict_with_mean(train_descriptors, test_descriptors, num_examples_per_face, threshold=None):\n",
    "    #     predictions = []\n",
    "    #     mean_train_descriptors = np.mean(np.reshape(train_descriptors, (-1, num_examples_per_face, 4096)), axis=1)\n",
    "\n",
    "    #     for d in test_descriptors:\n",
    "    #         distances = [np.linalg.norm(mean_train_descriptors[i] - d) for i in range(len(mean_train_descriptors))]\n",
    "    #         predictions.append(np.argmin(distances))\n",
    "    #     return np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(trained_model, manipulation_info):\n",
    "    _, _, test_data, test_targets = experiment.get_lfw_dfi_dataset(trained_model.min_faces_per_person, trained_model.num_train, manipulation_info, color=True, size=224)\n",
    "    test_descriptors = trained_model.get_descriptors(test_data)\n",
    "\n",
    "    # Test\n",
    "    print('Testing')\n",
    "    time1 = time.clock()\n",
    "    train_predictions_1 = trained_model.predict_train(1)\n",
    "    train_predictions_3 = trained_model.predict_train(3)\n",
    "    train_predictions_5 = trained_model.predict_train(5)\n",
    "    train_predictions_7 = trained_model.predict_train(7)\n",
    "    # train_accuracy = experiment.compute_accuracy(train_predictions, test_targets)\n",
    "    train_accuracy_1 = experiment.compute_accuracy(train_predictions_1, trained_model.train_targets)\n",
    "    train_accuracy_3 = experiment.compute_accuracy(train_predictions_3, trained_model.train_targets)\n",
    "    train_accuracy_5 = experiment.compute_accuracy(train_predictions_5, trained_model.train_targets)\n",
    "    train_accuracy_7 = experiment.compute_accuracy(train_predictions_7, trained_model.train_targets)\n",
    "    \n",
    "    # Predict test_descriptors\n",
    "    test_predictions_1 = trained_model.predict(test_descriptors, 1)\n",
    "    test_predictions_3 = trained_model.predict(test_descriptors, 3)\n",
    "    test_predictions_5 = trained_model.predict(test_descriptors, 5)\n",
    "    test_predictions_7 = trained_model.predict(test_descriptors, 7)\n",
    "    # test_accuracy = experiment.compute_accuracy(test_predictions, test_targets)\n",
    "    test_accuracy_1 = experiment.compute_accuracy(test_predictions_1, test_targets)\n",
    "    test_accuracy_3 = experiment.compute_accuracy(test_predictions_3, test_targets)\n",
    "    test_accuracy_5 = experiment.compute_accuracy(test_predictions_5, test_targets)\n",
    "    test_accuracy_7 = experiment.compute_accuracy(test_predictions_7, test_targets)\n",
    "    time2 = time.clock()\n",
    "    test_time = time2 - time1\n",
    "    \n",
    "    train_accuracy = { \"k=1\": train_accuracy_1, \n",
    "                      \"k=3\": train_accuracy_3, \n",
    "                      \"k=5\": train_accuracy_5, \n",
    "                      \"k=7\": train_accuracy_7 }\n",
    "    \n",
    "    test_accuracy = { \"k=1\": test_accuracy_1, \n",
    "                      \"k=3\": test_accuracy_3, \n",
    "                      \"k=5\": test_accuracy_5, \n",
    "                      \"k=7\": test_accuracy_7 }\n",
    "    \n",
    "    # Print results.\n",
    "    num_faces = len(np.unique(trained_model.train_targets))\n",
    "    model_name = 'VGG_FACE'\n",
    "    print(\"Manipulation info: %s\" % str(manipulation_info))\n",
    "    print(\"Recognition Algorithm: %s\" % model_name)\n",
    "    print(\"Number of distinct faces: %d\" % num_faces)\n",
    "    print(\"Chance rate: %f\" % (1 / num_faces))\n",
    "    print(\"Train accuracy: %s\" % train_accuracy)\n",
    "    print(\"Test accuracy: %s\" % test_accuracy)\n",
    "    print(\"Training Time: %s sec\" % trained_model.train_time)\n",
    "    print(\"Testing Time: %s sec\" % test_time)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"Manipulation Type\": manipulation_info.type,\n",
    "        \"Manipulation Parameters\": manipulation_info.parameters,\n",
    "        \"Recognition Algorithm\": model_name,\n",
    "        \"Min Faces Per Person\": trained_model.min_faces_per_person,\n",
    "        \"Number of Distinct Faces\": num_faces,\n",
    "        \"Chance Rate\": (1 / num_faces),\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy,\n",
    "        \"Training Time\": trained_model.train_time,\n",
    "        \"Testing Time\": test_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training examples: 3\n",
      "Loading model\n",
      "Loading training dataset\n",
      "Training\n",
      "186/186 [==============================] - 9s     \n",
      "Training time: 10.108147\n",
      "613/613 [==============================] - 13s    \n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='dfi', parameters={'transform': 'Senior'})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=5': 0.478494623655914, 'k=1': 1.0, 'k=7': 0.45161290322580644, 'k=3': 0.54838709677419351}\n",
      "Test accuracy: {'k=5': 0.15497553017944535, 'k=1': 0.15171288743882544, 'k=7': 0.15660685154975529, 'k=3': 0.14681892332789559}\n",
      "Training Time: 10.108146999999999 sec\n",
      "Testing Time: 26.095492000000007 sec\n",
      "\n",
      "\n",
      "{'Training Time': 10.108146999999999, 'Test Accuracy': {'k=5': 0.15497553017944535, 'k=1': 0.15171288743882544, 'k=7': 0.15660685154975529, 'k=3': 0.14681892332789559}, 'Train Accuracy': {'k=5': 0.478494623655914, 'k=1': 1.0, 'k=7': 0.45161290322580644, 'k=3': 0.54838709677419351}, 'Number of Distinct Faces': 62, 'Min Faces Per Person': 20, 'Recognition Algorithm': 'VGG_FACE', 'Chance Rate': 0.016129032258064516, 'Manipulation Type': 'dfi', 'Manipulation Parameters': {'transform': 'Senior'}, 'Testing Time': 26.095492000000007}\n",
      "\n",
      "613/613 [==============================] - 12s    \n",
      "Testing\n",
      "Manipulation info: ManipulationInfo(type='dfi', parameters={'transform': 'Mustache'})\n",
      "Recognition Algorithm: VGG_FACE\n",
      "Number of distinct faces: 62\n",
      "Chance rate: 0.016129\n",
      "Train accuracy: {'k=5': 0.478494623655914, 'k=1': 1.0, 'k=7': 0.45161290322580644, 'k=3': 0.54838709677419351}\n",
      "Test accuracy: {'k=5': 0.19249592169657423, 'k=1': 0.19902120717781402, 'k=7': 0.18760195758564438, 'k=3': 0.18760195758564438}\n",
      "Training Time: 10.108146999999999 sec\n",
      "Testing Time: 26.13689500000001 sec\n",
      "\n",
      "\n",
      "{'Training Time': 10.108146999999999, 'Test Accuracy': {'k=5': 0.19249592169657423, 'k=1': 0.19902120717781402, 'k=7': 0.18760195758564438, 'k=3': 0.18760195758564438}, 'Train Accuracy': {'k=5': 0.478494623655914, 'k=1': 1.0, 'k=7': 0.45161290322580644, 'k=3': 0.54838709677419351}, 'Number of Distinct Faces': 62, 'Min Faces Per Person': 20, 'Recognition Algorithm': 'VGG_FACE', 'Chance Rate': 0.016129032258064516, 'Manipulation Type': 'dfi', 'Manipulation Parameters': {'transform': 'Mustache'}, 'Testing Time': 26.13689500000001}\n",
      "\n",
      "\n",
      "\n",
      "Num training examples: 10\n",
      "Loading model\n",
      "Loading training dataset\n",
      "Training\n",
      "620/620 [==============================] - 14s    \n",
      "Training time: 15.316422\n",
      "288/613 [=============>................] - ETA: 6s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-57dbbb646868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmanipulation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmanipulation_infos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanipulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7ddd586c8b10>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(trained_model, manipulation_info)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanipulation_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lfw_dfi_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_faces_per_person\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanipulation_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_descriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0959f4ae3b10>\u001b[0m in \u001b[0;36mget_descriptors\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mdescriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1713\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/Keras-2.0.8-py3.5.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "manipulation_infos = [\n",
    "        ManipulationInfo(\"dfi\", {\"transform\": \"Senior\"}),\n",
    "        ManipulationInfo(\"dfi\", {\"transform\": \"Mustache\"}),\n",
    "    ]\n",
    "\n",
    "num_trains = [3, 10, 15, 19]\n",
    "for num_train in num_trains:\n",
    "    print(\"Num training examples: %d\" % num_train)\n",
    "    save_path = \"vgg_face_dfi_%d.csv\" % num_train\n",
    "    results = pd.DataFrame(columns=experiment.COLUMNS)\n",
    "    trained_model = TrainedModel(num_train)\n",
    "    for manipulation in manipulation_infos:\n",
    "        stats = run_experiment(trained_model, manipulation)\n",
    "        results.append(stats, ignore_index=True)\n",
    "        print(stats)\n",
    "        print()\n",
    "    results.to_csv(save_path, index=False)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Graphs\n",
    "\n",
    "# # Accuracy as a function of k for 3 training images\n",
    "# # With and without preprocessing\n",
    "# # Mean/Euclidean distance included as a line\n",
    "\n",
    "# accuracy = np.array([0.8808600634473035, 0.83785689108212902, 0.83080719069439546, 0.79978850898836795])\n",
    "# preprocessed_accuracy = np.array([0.96686640817765246, 0.96263658794501239, 0.94360239689813186, 0.9002467395135707])\n",
    "# k = np.array([1, 3, 5, 7])\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# width = 0.35\n",
    "# acc1 = ax.bar(k, accuracy, width, label='No preprocessing')\n",
    "# acc2 = ax.bar(k+width, preprocessed_accuracy, width, label='Preprocessed')\n",
    "# ax.plot([0, 8], [0.85442368699330273, 0.85442368699330273], 'k-', lw=1, linestyle='dashed')\n",
    "# ax.set_xticks(k)\n",
    "# ax.set_xlabel('$k$')\n",
    "# ax.set_ylabel('Accuracy')\n",
    "# ax.set_title('VGG_FACE accuracy on LFW with varying $k$ and 3 training images')\n",
    "# legend = ax.legend(handles=[acc1, acc2], loc=4)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
